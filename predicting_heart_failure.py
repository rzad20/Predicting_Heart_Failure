# -*- coding: utf-8 -*-
"""Predicting_Heart_Failure.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13oqFHi9VG0eSL-txL9x6eLqxIdMRP5GL

# Analisa Kinerja Metode *K-Nearest Neighbor*, Logistic Regression, dan Decision Tree dalam mengklasifikasi pasien berisiko terkena penyakit gagal jantung

* **Nama**: Rizky Aditya
* **Email**: rizky.aditya41119@gmail.com
* **ID Dicoding**: rzad20
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Tahap 1 : Mengimpor Semua Packages / Library yang dibutuhkan

"""

import pandas as pd
import numpy as np

#Untuk Visualisasi Data
import matplotlib.pyplot as plt
import seaborn as sns

#Library yang dibutuhkan untuk proses Machine Learning
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_absolute_error, classification_report,mean_squared_error

"""## Tahap 2 : Data Loading"""

#Memasukkan dataset
data_path = '/content/drive/MyDrive/ML_Project_Data/heart.csv'
dataset = pd.read_csv(data_path)
dataset.head()

"""## Tahap 3 - Deksripsi Variabel data dan Penilaian Data

Berdasarkan informasi dari Sumber Dataset, variabel-variabel yang terdapat dalam dataset terkait adalah sebagai berikut :
1. Age : Usia Pasien Dalam Tahun.
2. Sex : Jenis Kelamin Pasien (M : Male/Laki-Laki, F : Female/Perempuan).
3. ChestPainType : Jenis Nyeri dada yang dialami pasien (TA : Angina Tipikal, ATA : Angina Atipikal, NAP : Nyeri Dada Non Anginal, ASY : Asimtomatik).
4. RestingBp : Tekanan darah istirahat pasien dalam satuan mm Hg (milimeter air raksa)
Cholestrol : Kolestrol serum pasien dalam satuan mm/dl.
5. FastingBS : Kadar gula darah puasa pasien [1: Jika FastingBS>120 mg/dl, 0: sebaliknya].
6. RestingECG : Hasil elektrokardiogram istirahat pasien (Normal: Normal, ST: Abnormalitas gelombang ST-T (Inversi gelombang T dan/atau elevasi atau depresi ST > 0.05 mV).
7. LVH: Kemungkinan atau pasti hipertrofi ventrikel kiri menurut kriteria Estes)
8. MaxHR : Denyut jantung maksimum yang dicapai oleh pasien (Nilai Numerik antara 60 dan 202)
9. ExerciseAngina : Angina yang dipicu oleh latihan (Y : Ya, N : Tidak)
10. Oldpeak : Depresi segmen T (Nilai numerik diukur dalam depresi)
11. ST_Slope : Kemiringan segmen ST latihan puncak (Up : Naik, Flat : Datar, Down : Turun)
12. HeartDisease : Kelas keluaran (1: memiliki penyakit jantung, 0 : Normal)
"""

#Melihat Informasi Pada Data
dataset.info()

#Melihat Deksripsi Seluruh Data
dataset.describe(include="all")

#Mencari tahu apakah ada duplikasi dalam data
print("jumlah duplikasi :" ,dataset.duplicated().sum())

#Mencari tahu apakah ada missing values dalam data
dataset.isna().sum()

"""### Identifikasi Outlier dengan boxplot"""

num_cols=dataset.select_dtypes(include=['number']).columns
fig, axes = plt.subplots(len(num_cols), 1, figsize=(8, 6 * len(num_cols)))
axes = axes.flatten()
for i, column in enumerate(dataset[num_cols]):
    sns.boxplot(x=dataset[column], ax=axes[i])
    axes[i].set_title(f'box for {column}')
    axes[i].set_xlabel(column)

plt.tight_layout(h_pad=2, w_pad=2)
plt.show()

Q1 = dataset.quantile(0.25)
Q3 = dataset.quantile(0.75)
IQR=Q3-Q1
dataset=dataset[~((dataset<(Q1-1.5*IQR))|(dataset>(Q3+1.5*IQR))).any(axis=1)]

# Cek ukuran dataset setelah kita drop outliers
dataset.shape

"""Setelah dilakukan penilaian, ternyata tidak ada nilai yang hilang (missing values) dalam data dan tidak ada duplikasi data. Outlier dalam data juga sudah ditangani sehingga data saat ini berubah menjadi 588 Baris.
Namun, beberapa kolom dalam data masih bersifat kategorikal. Kolom-kolom data tersebut akan diubah menjadi numerik menggunakan label encoder dalam tahap pemrosesan data berikutnya.

Beberapa kolom data juga memiliki nilai yang cenderung besar. Ini akan ditangani dengan menggunakan Standard Scaler dalam tahap pemrosesan data selanjutnya.

## Tahap 4 - Univariate Analysis

### Distribusi Data-Data Categorical

Distribusi data berdasarkan jenis kelamin
"""

feature = 'Sex'
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
count.plot(kind='bar', title=feature)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)

"""Distribusi Data Berdasarkan ChestPainType"""

feature = 'ChestPainType'
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""Distribusi Berdasarkan RestingECG"""

feature = 'RestingECG'
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
count.plot(kind='bar', title=feature)
print(df)

"""Berdasarkan Exercise Angina"""

feature = 'ExerciseAngina'
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
count.plot(kind='bar', title=feature)
print(df)

"""Berdasarkan ST_Slope"""

feature = 'ST_Slope'
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
count.plot(kind='bar', title=feature)
print(df)

"""Distribusi Data Variabel Target"""

types = dataset['HeartDisease'].value_counts()
colors = ['#F57D1F','#EBF400']

# Create a two-subplot layout
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

# Bar chart on the first subplot
ax1.barh(y=types.index, width=types.values, color=colors)
ax1.set_xlabel('Frequency')
ax1.set_ylabel('Penyakit Jantung')
ax1.grid(alpha=0.4)

# Pie chart on the second subplot
ax2.pie(types.values, labels=types.index, explode=([0.05] * len(types.index)), colors=colors, autopct='%.2f%%')

# Configure the overall layout
fig.suptitle('Distribution Data berdasarkan Resiko Penyakit', fontsize=15)
plt.tight_layout(pad=1)
plt.show()

"""### Distribusi Numerical Features"""

#membuat histogram untuk melihat distribusi data numerical
dataset.hist(bins=50,figsize=(20,15))
plt.show()

"""## Tahap 5 - Multivariate Analysis

### Analisa Terhadap Categorical Features
Dalam tahap ini, kita akan mengecek pengaruh masing masing
data ketegorikal terhadap berisiko atau tidaknya seseorang
dalam mengalami penyakit gagal jantung
"""

fitur_kategorikal = dataset.select_dtypes(include='object').columns.to_list()
for kolom in fitur_kategorikal:
  sns.catplot(x=kolom, y="HeartDisease"  , kind="bar", dodge=False, height = 4, aspect = 3,  data=dataset, palette="Set3")
  plt.title("Risiko Terkena 'Gagal Jantung' Relatif terhadap - {}".format(kolom))

"""### Pengecekan Korelasi Kategori Numerical"""

plt.figure(figsize=(10, 8))
correlation_matrix = dataset.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""## Tahap 6 - Data Preparation

### Mengubah Fitur Kategorical menjadi numerical (angka) dengan bantuan label encoder
"""

encoder = LabelEncoder()
fitur_kategorikal = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']
kolom_kategorikal = dataset[fitur_kategorikal]
encoded_kategorikal = kolom_kategorikal.apply(encoder.fit_transform)
dataset[fitur_kategorikal] = encoded_kategorikal

#Cek Dataset setelah diberi labelencoder
dataset.head()

#Cek Info Dataset setelah diberi labelencoder
dataset.info()

dataset.describe()

"""## Standardisasi
langkah ini merupakan transformasi data agar skala data relatif sama atau mendekati distribusi normal agar lebih mudah diolah oleh algoritma
"""

numerical_features = ['Age', 'RestingBP', 'Cholesterol', 'Oldpeak' , 'MaxHR']
scaler = MinMaxScaler()
scaler.fit(dataset[numerical_features])
dataset[numerical_features] = scaler.transform(dataset.loc[:, numerical_features])
dataset[numerical_features].head()

dataset.describe()

"""## Train Test Split
Langkah selanjutnya adalah membagi Dataset menjadi Data Latih dan Data Uji menggunakan Train_Test_Split
"""

X = dataset.drop(["HeartDisease"], axis=1)
y = dataset['HeartDisease']
X_train, X_test, y_train,y_test = train_test_split(X,y, test_size = 0.20, random_state=123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## Tahap 7 - Analisa Model Machine Learning

### Analisa Menggunakan K-Nearest Neighbor
"""

#Analisa menggunakan KNN dengan menggunakan jumlah K=3
Model_KNN = KNeighborsClassifier(n_neighbors=3)
Model_KNN.fit(X_train,y_train)

#Evaluasi Model terhadap Data Latih
y_train_pred = Model_KNN.predict(X_train)
KNN_acc_train = accuracy_score(y_train, y_train_pred)

print(f"Akurasi Train : {round(KNN_acc_train * 100,2)}%")

#Evaluasi Model terhadap Data Uji
y_test_pred = Model_KNN.predict(X_test)
KNN_acc_test = accuracy_score(y_test, y_test_pred)
print(f"Akurasi Test : {round(KNN_acc_test * 100,2)}%")

#Visualisasi Menggunakan Confussion Matrix
matrix = confusion_matrix(y_test, y_test_pred)
sns.heatmap(matrix, annot=True, fmt='d', cmap='Reds', cbar=False,)
plt.title('Confussion matrix dengan KNN');
# Print classification report
print("Classification report: \n{}".format(classification_report(y_test, y_test_pred)))
KNN_precision = precision_score(y_test,y_test_pred)
KNN_recall = recall_score(y_test,y_test_pred)
KNN_f1 = f1_score(y_test,y_test_pred)

"""## Analisa Menggunakan Logistic Regression"""

lr_model = LogisticRegression()
lr_model.fit(X_train,y_train)

#Evaluasi Model terhadap Data Latih
lr_train_pred = lr_model.predict(X_train)
lr_acc_train = accuracy_score(y_train, lr_train_pred)
print(f"Akurasi Train dengan LR : {round(lr_acc_train * 100,2)}%")

#Evaluasi Model terhadap Data Uji
lr_test_pred = lr_model.predict(X_test)
lr_acc_test = accuracy_score(y_test, lr_test_pred)
print(f"Akurasi Train dengan LR : {round(lr_acc_test * 100,2)}%")

#Visualisasi Menggunakan Confussion Matrix
matrix = confusion_matrix(y_test, lr_test_pred)
sns.heatmap(matrix, annot=True, fmt='d', cmap='Reds', cbar=False,)
plt.title('Confussion matrix dengan LR');
# Print classification report
print("Classification report: \n{}".format(classification_report(y_test, lr_test_pred)))
lr_precision = precision_score(y_test,lr_test_pred)
lr_recall = recall_score(y_test,lr_test_pred)
lr_f1 = f1_score(y_test,lr_test_pred)

"""## Analisa Menggunakan Decision Tree"""

decisiontreemodel = DecisionTreeClassifier()
decisiontreemodel.fit(X_train,y_train)

#Evaluasi Model terhadap Data Latih
tree_train_pred = decisiontreemodel.predict(X_train)
tree_acc_train = accuracy_score(y_train, tree_train_pred)
print(f"Akurasi Train dengan Decision Tree : {round(tree_acc_train * 100,2)}%")

#Evaluasi Model terhadap Data Uji
tree_test_pred = decisiontreemodel.predict(X_test)
tree_acc_test = accuracy_score(y_test, tree_test_pred)
print(f"Akurasi Test dengan Decision Tree : {round(tree_acc_test * 100,2)}%")

#Visualisasi Menggunakan Confussion Matrix
matrix = confusion_matrix(y_test, tree_test_pred)
sns.heatmap(matrix, annot=True, fmt='d', cmap='Reds', cbar=False,)
plt.title('Confussion matrix dengan LR');
# Print classification report
print("Classification report: \n{}".format(classification_report(y_test, tree_test_pred)))
tree_precision = precision_score(y_test,tree_test_pred)
tree_recall = recall_score(y_test,tree_test_pred)
tree_f1 = f1_score(y_test,tree_test_pred)

"""## Kesimpulan

Berikut merupakan perbandingan Accuracy Train, Accuracy Test, Precission, Recall, dan F1 Score untuk mengukur kinerja masing masing Algoritma
"""

models = pd.DataFrame({
    'Model':
    ['K-Nearest Neighbor', 'Logistic Regression', 'Decision Tree'],
    'Accuracy Test' :
    [KNN_acc_test, lr_acc_test, tree_acc_test],
    'Accuracy Train' :
    [KNN_acc_train, lr_acc_train, tree_acc_train],
    'Precision' :
    [KNN_precision,lr_precision, tree_precision],
    'Recall' :
    [KNN_recall,lr_recall,tree_recall],
    'F1 Score' :
    [KNN_f1, lr_f1,tree_f1]
})
models

